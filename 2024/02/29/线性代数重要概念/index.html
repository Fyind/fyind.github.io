<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>线性代数重要概念 | Fyind's Blog</title><meta name="author" content="Fyind"><meta name="copyright" content="Fyind"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="Matrix Algebra 列表示 \[ A&#x3D;\left[\begin{array}{llll} \mathbf{a}_1 &amp; \mathbf{a}_2 &amp; \cdots &amp; \mathbf{a}_n \end{array}\right] \] 定理 基本运算 Let \(A,B,C\) be matrices of the same size, and \(r,s\)">
<meta property="og:type" content="article">
<meta property="og:title" content="线性代数重要概念">
<meta property="og:url" content="http://fyind.de/2024/02/29/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E9%87%8D%E8%A6%81%E6%A6%82%E5%BF%B5/index.html">
<meta property="og:site_name" content="Fyind&#39;s Blog">
<meta property="og:description" content="Matrix Algebra 列表示 \[ A&#x3D;\left[\begin{array}{llll} \mathbf{a}_1 &amp; \mathbf{a}_2 &amp; \cdots &amp; \mathbf{a}_n \end{array}\right] \] 定理 基本运算 Let \(A,B,C\) be matrices of the same size, and \(r,s\)">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://fyind.de/img/pic1.PNG">
<meta property="article:published_time" content="2024-02-29T16:33:43.000Z">
<meta property="article:modified_time" content="2025-07-18T10:49:53.882Z">
<meta property="article:author" content="Fyind">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://fyind.de/img/pic1.PNG"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "线性代数重要概念",
  "url": "http://fyind.de/2024/02/29/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E9%87%8D%E8%A6%81%E6%A6%82%E5%BF%B5/",
  "image": "http://fyind.de/img/pic1.PNG",
  "datePublished": "2024-02-29T16:33:43.000Z",
  "dateModified": "2025-07-18T10:49:53.882Z",
  "author": [
    {
      "@type": "Person",
      "name": "Fyind",
      "url": "http://fyind.de"
    }
  ]
}</script><link rel="shortcut icon" href="/img/pic1.PNG"><link rel="canonical" href="http://fyind.de/2024/02/29/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E9%87%8D%E8%A6%81%E6%A6%82%E5%BF%B5/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: 'Copy Successful',
    error: 'Copy Failed',
    noSupport: 'Browser Not Supported'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: 'Just now',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: 'Load More'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '线性代数重要概念',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><meta name="generator" content="Hexo 7.3.0"></head><body><div id="web_bg" style="background-image: url(https://fyindex.work/PicGo/liuyin.jpg);"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="/img/pic1.PNG" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">85</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">83</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">26</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/categories/TUM%E7%AC%94%E8%AE%B0"><i class="fa-fw fas fa-folder-open"></i><span> TUM笔记</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友情链接</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(/img/yae.jpg);"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">Fyind's Blog</span></a><a class="nav-page-title" href="/"><span class="site-name">线性代数重要概念</span><span class="site-name"><i class="fa-solid fa-circle-arrow-left"></i><span>  Back to Home</span></span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/categories/TUM%E7%AC%94%E8%AE%B0"><i class="fa-fw fas fa-folder-open"></i><span> TUM笔记</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友情链接</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">线性代数重要概念</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2024-02-29T16:33:43.000Z" title="Created 2024-02-29 16:33:43">2024-02-29</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2025-07-18T10:49:53.882Z" title="Updated 2025-07-18 10:49:53">2025-07-18</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post Views:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><h2 id="matrix-algebra">Matrix Algebra</h2>
<p>列表示 <span class="math display">\[
A=\left[\begin{array}{llll}
\mathbf{a}_1 &amp; \mathbf{a}_2 &amp; \cdots &amp; \mathbf{a}_n
\end{array}\right]
\]</span></p>
<h3 id="定理-基本运算">定理 基本运算</h3>
<p>Let <span class="math inline">\(A,B,C\)</span> be matrices of the
same size, and <span class="math inline">\(r,s\)</span> be scalars</p>
<ul>
<li><span class="math inline">\(A+B=B+A\)</span></li>
<li><span class="math inline">\((A+B)+C=A+(B+C)\)</span></li>
<li><span class="math inline">\(A+0=A\)</span></li>
<li><span class="math inline">\(r(A+B)=rA+rB\)</span></li>
<li><span class="math inline">\((r+s)A = rA + sA\)</span></li>
<li><span class="math inline">\(r(sA)=(rs)A\)</span></li>
</ul>
<p>scalar 可以交换位置 <span class="math display">\[
\lambda(\boldsymbol{B} \boldsymbol{C})=(\lambda \boldsymbol{B})
\boldsymbol{C}=\boldsymbol{B}(\lambda \boldsymbol{C})=(\boldsymbol{B}
\boldsymbol{C}) \lambda, \quad \boldsymbol{B} \in \mathbb{R}^{m \times
n}, \boldsymbol{C} \in \mathbb{R}^{n \times k}
\]</span> transpose 不影响 <span class="math display">\[
(\lambda \boldsymbol{C})^{\top}=\boldsymbol{C}^{\top}
\lambda^{\top}=\boldsymbol{C}^{\top} \lambda=\lambda \boldsymbol{C}
\]</span></p>
<h3 id="matrix-multiplication">Matrix Multiplication</h3>
<p>When matrix <span class="math inline">\(B\)</span> multiplies a
vector <span class="math inline">\(x\)</span> , it transfer <span
class="math inline">\(x\)</span> into vector <span
class="math inline">\(Bx\)</span></p>
<p><img src="https://fyindex.work/PicGo/image-20240301080200127.png"
alt="image-20240301080200127" /> <span class="math display">\[
A(Bx)=(AB)x
\]</span> if <span class="math inline">\(A\)</span> is <span
class="math inline">\(m\times n\)</span> , <span
class="math inline">\(B\)</span> is <span class="math inline">\(n \times
p\)</span> , and <span class="math inline">\(x\)</span> in <span
class="math inline">\(R^p\)</span> <span class="math display">\[
B \mathbf{x}=x_1 \mathbf{b}_1+\cdots+x_p \mathbf{b}_p
\]</span></p>
<p><span class="math display">\[
\pi_U(\boldsymbol{x})=\sum_{i=1}^m \lambda_i
\boldsymbol{b}_i=\boldsymbol{B} \boldsymbol{\lambda},
\]</span></p>
<p><span class="math display">\[
A B=A\left[\begin{array}{llll}
\mathbf{b}_1 &amp; \mathbf{b}_2 &amp; \cdots &amp; \mathbf{b}_p
\end{array}\right]=\left[\begin{array}{llll}
A \mathbf{b}_1 &amp; A \mathbf{b}_2 &amp; \cdots &amp; A \mathbf{b}_p
\end{array}\right]
\]</span></p>
<p><span class="math display">\[
AD = [\lambda_1 A, \lambda_2 A, ... , \lambda_n A]
\]</span></p>
<p><span class="math inline">\(D\)</span> is diagoal</p>
<h3 id="定理-乘法的性质">定理 乘法的性质</h3>
<p><span class="math inline">\(I_m\)</span> is <span
class="math inline">\(m \times m\)</span> identity matrix, <span
class="math inline">\(I_m \mathbf{x} = \mathbf{x}\)</span> , <span
class="math inline">\(A\)</span> is <span class="math inline">\(m\times
n\)</span>, <span class="math inline">\(\mathbf{x}\)</span> is in <span
class="math inline">\(\mathbb{R}^m\)</span></p>
<ul>
<li><span class="math inline">\(A(BC)=(AB)C\)</span></li>
<li><span class="math inline">\(A(B+C)=AB+AC\)</span></li>
<li><span class="math inline">\((B+C)A=BA+CA\)</span></li>
<li><span class="math inline">\(r(AB)=(rA)B=A(rB)\)</span></li>
<li><span class="math inline">\(I_mA=A=AI_n\)</span></li>
</ul>
<h3 id="the-transpose-of-a-matrix">The Transpose of a Matrix</h3>
<ul>
<li><span class="math inline">\((A^T)^T=A\)</span></li>
<li><span class="math inline">\((A+B)^T=A^T + B^T\)</span></li>
<li><span class="math inline">\((rA)^T=r(A^T)\)</span></li>
<li><span class="math inline">\((AB)^T=B^TA^T\)</span></li>
</ul>
<h3 id="inverse-matrix">inverse matrix</h3>
<ul>
<li><p><span class="math inline">\(A^{-1}A=AA^{-1}=I\)</span></p></li>
<li><p><span class="math inline">\((A^{-1})^{-1}=A\)</span></p></li>
<li><p><span
class="math inline">\((AB)^{-1}=B^{-1}A^{-1}\)</span></p></li>
<li><p><span class="math inline">\((A^T)^{-1}=
(A^{-1})^T\)</span></p></li>
</ul>
<h2 id="vector-space-and-subspaces">vector space and subspaces</h2>
<h3 id="vector-space">vector space</h3>
<p>vector space is nonempty set <span class="math inline">\(V\)</span>
of vectors.</p>
<ul>
<li>两个向量相加在里面</li>
<li>和scalar 乘在里面</li>
<li><span class="math inline">\(0\in V\)</span></li>
</ul>
<h3 id="subspace">subspace</h3>
<p>vector space 且是另一个vector space 的子集</p>
<h3 id="the-null-space-of-a-matrix">The Null Space of a Matrix</h3>
<p><span class="math inline">\(Ax=0\)</span> , the set of <span
class="math inline">\(x\)</span> is the null space of <span
class="math inline">\(A\)</span></p>
<h3 id="properties-of-determinants">Properties of Determinants</h3>
<ul>
<li><p><span class="math inline">\(A\)</span> is invertible if and only
if <span class="math inline">\(det(A) \ne 0\)</span></p></li>
<li><p><span class="math inline">\(det(AB) =
det(A)det(B)\)</span></p></li>
<li><p><span class="math inline">\(det(A^T)=det(A)\)</span></p></li>
<li><p>if <span class="math inline">\(A\)</span> is triangular, <span
class="math inline">\(det(A)=\)</span> product of entries in the main
diagonal</p></li>
<li><p>Row replacement doesn’t change determinant</p></li>
</ul>
<h3 id="find-span">Find span</h3>
<p>Find span of mull space of the matrix <span
class="math inline">\(A=\left[\begin{array}{rrrrr}-3 &amp; 6 &amp; -1
&amp; 1 &amp; -7 \\ 1 &amp; -2 &amp; 2 &amp; 3 &amp; -1 \\ 2 &amp; -4
&amp; 5 &amp; 8 &amp; -4\end{array}\right]\)</span></p>
<p>先化成 <span class="math inline">\(\left[\begin{array}{rrrrrr}1 &amp;
-2 &amp; 0 &amp; -1 &amp; 3 &amp; 0 \\ 0 &amp; 0 &amp; 1 &amp; 2 &amp;
-2 &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp;
0\end{array}\right]\)</span></p>
<p>然后列式子 <span class="math display">\[
\begin{aligned}
x_1-2 x_2-x_4+3 x_5 &amp; =0 \\
x_3+2 x_4-2 x_5 &amp; =0 \\
0 &amp; =0
\end{aligned}
\]</span> 所以看出 <span class="math display">\[
\left[\begin{array}{c}
x_1 \\
x_2 \\
x_3 \\
x_4 \\
x_5
\end{array}\right]=\left[\begin{array}{c}
2 x_2+x_4-3 x_5 \\
x_2 \\
-2 x_4+2 x_5 \\
x_4 \\
x_5
\end{array}\right]=x_2\left[\begin{array}{l}
2 \\
1 \\
0 \\
0 \\
0
\end{array}\right]+x_4\left[\begin{array}{r}
1 \\
0 \\
-2 \\
1 \\
0
\end{array}\right]+x_5\left[\begin{array}{r}
-3 \\
0 \\
2 \\
0 \\
1
\end{array}\right]
\]</span> 那些就是要求的 Base vectors</p>
<h3 id="rank">Rank</h3>
<ul>
<li><span
class="math inline">\(\operatorname{rk}(\boldsymbol{A})=\operatorname{rk}\left(\boldsymbol{A}^{\top}\right)\)</span>
row rank = col rank</li>
<li>for square matrix <span
class="math inline">\(\boldsymbol{A}\)</span> is regular (invertible) if
and only if <span
class="math inline">\(\operatorname{rk}(\boldsymbol{A})=n\)</span></li>
</ul>
<h2 id="linear-mapping">Linear Mapping</h2>
<p><span class="math display">\[
\forall \boldsymbol{x}, \boldsymbol{y}  \in V \ \forall \lambda, \psi
\in \mathbb{R}: \Phi(\lambda \boldsymbol{x}+\psi \boldsymbol{y})=\lambda
\Phi(\boldsymbol{x})+\psi \Phi(\boldsymbol{y})
\]</span></p>
<p>we have to keep in mind what the matrix represents: a linear mapping
or a collection of vectors</p>
<h4 id="image">Image</h4>
<p><span class="math display">\[
\operatorname{Im}(\Phi):=\Phi(V)=\{\boldsymbol{w} \in W \mid \exists
\boldsymbol{v} \in V: \Phi(\boldsymbol{v})=\boldsymbol{w}\}
\]</span></p>
<h3 id="null-space-and-column-space">Null Space and Column Space</h3>
<p><span class="math inline">\(\boldsymbol{A}=\left[\boldsymbol{a}_1,
\ldots, \boldsymbol{a}_n\right]\)</span>, where <span
class="math inline">\(\boldsymbol{a}_i\)</span> are the columns of <span
class="math inline">\(\boldsymbol{A}\)</span>, <span
class="math display">\[
\begin{aligned}
\operatorname{Im}(\Phi) &amp; =\left\{\boldsymbol{A} \boldsymbol{x}:
\boldsymbol{x} \in \mathbb{R}^n\right\}=\left\{\sum_{i=1}^n x_i
\boldsymbol{a}_i: x_1, \ldots, x_n \in \mathbb{R}\right\} \\
&amp; =\operatorname{span}\left[\boldsymbol{a}_1, \ldots,
\boldsymbol{a}_n\right] \subseteq \mathbb{R}^m
\end{aligned}
\]</span></p>
<p><span class="math display">\[
\operatorname{rk}(\boldsymbol{A})=\operatorname{dim}(\operatorname{Im}(\Phi))
\]</span></p>
<p>For vector spaces <span class="math inline">\(V, W\)</span> and
linear mapping <span class="math inline">\(\Phi: V \rightarrow
W\)</span> : <span class="math display">\[
\operatorname{dim}(\operatorname{ker}(\Phi))+\operatorname{dim}(\operatorname{Im}(\Phi))=\operatorname{dim}(V)
\]</span></p>
<h3 id="transformation-matrix">Transformation Matrix</h3>
<p><span class="math display">\[
\hat{\boldsymbol{y}}=\boldsymbol{A}_{\Phi} \hat{\boldsymbol{x}}
\]</span></p>
<p>t the transformation matrix can be used to map coordinates with
respect to an ordered basis in V to coordinates with respect to an
ordered basis in W.</p>
<h2 id="traces">Traces</h2>
<h3 id="properties">properties</h3>
<p><span class="math display">\[
\operatorname{tr}(\boldsymbol{A}+\boldsymbol{B})=\operatorname{tr}(\boldsymbol{A})+\operatorname{tr}(\boldsymbol{B})
\text { for } \boldsymbol{A}, \boldsymbol{B} \in \mathbb{R}^{n \times n}
\]</span></p>
<p><span class="math display">\[
\operatorname{tr}(\alpha \boldsymbol{A})=\alpha
\operatorname{tr}(\boldsymbol{A}), \alpha \in \mathbb{R} \text { for }
\boldsymbol{A} \in \mathbb{R}^{n \times n}
\]</span></p>
<p><span class="math display">\[
\operatorname{tr}\left(\boldsymbol{I}_n\right)=n
\]</span></p>
<p><span class="math display">\[
\operatorname{tr}(\boldsymbol{A}
\boldsymbol{B})=\operatorname{tr}(\boldsymbol{B} \boldsymbol{A}) \text {
for } \boldsymbol{A} \in \mathbb{R}^{n \times k}, \boldsymbol{B} \in
\mathbb{R}^{k \times n}
\]</span></p>
<p>the trace is invariant under cyclic permutations <span
class="math display">\[
\operatorname{tr}(\boldsymbol{A} \boldsymbol{K}
\boldsymbol{L})=\operatorname{tr}(\boldsymbol{K} \boldsymbol{L}
\boldsymbol{A})
\]</span></p>
<p><span class="math display">\[
\operatorname{tr}\left(\boldsymbol{x}
\boldsymbol{y}^{\top}\right)=\operatorname{tr}\left(\boldsymbol{y}^{\top}
\boldsymbol{x}\right)=\boldsymbol{y}^{\top} \boldsymbol{x} \in
\mathbb{R}
\]</span></p>
<h2 id="eignevalue-and-eigenvector">Eignevalue and Eigenvector</h2>
<p><span class="math inline">\(\mathbf{x} \mapsto A \mathbf{x}\)</span>
我们称之为一个变换，它会把vector <span class="math inline">\(x\)</span>
变成不同的方向，但是有一些 <span class="math inline">\(x\)</span>
很特殊，它的变换很简单, 比如</p>
<p><span class="math inline">\(A=\left[\begin{array}{rr}3 &amp; -2 \\ 1
&amp; 0\end{array}\right], \mathbf{u}=\left[\begin{array}{r}-1 \\
1\end{array}\right]\)</span>, and <span
class="math inline">\(\mathbf{v}=\left[\begin{array}{l}2 \\
1\end{array}\right]\)</span></p>
<figure>
<img src="https://fyindex.work/PicGo/image-20240229163612417.png"
alt="image-20240229163612417" />
<figcaption aria-hidden="true">image-20240229163612417</figcaption>
</figure>
<p>对于 <span class="math inline">\(v\)</span>
来说，只是伸展了。这里，我们研究那些只会伸展的向量</p>
<h3 id="eigenvector">Eigenvector</h3>
<p>matrix <span class="math inline">\(A\)</span> 的
<strong>eigenvector</strong> 是一个 non-zero vector <span
class="math inline">\(x\)</span> 使得 <span
class="math inline">\(Ax=\lambda x\)</span> A scalar is called an
<strong>eigenvalue</strong> of A if there is a nontrivial solution <span
class="math inline">\(x\)</span></p>
<p>The null space of <span class="math inline">\(A-\lambda I\)</span> is
a subspace of <span class="math inline">\(R^n\)</span> and is called the
eigenspace of <span class="math inline">\(A\)</span> corresponding to
<span class="math inline">\(\lambda\)</span></p>
<blockquote>
<p>the eigenspace corresponding to <span
class="math inline">\(\lambda=7\)</span> consists of all multiples of
<span class="math inline">\((1,1)\)</span>, which is the line through
<span class="math inline">\((1,1)\)</span> and the origin</p>
</blockquote>
<p>在eigenspace上的向量eigenvector在<span
class="math inline">\(A\)</span> 的变换下就是乘上 <span
class="math inline">\(\lambda\)</span></p>
<figure>
<img src="https://fyindex.work/PicGo/image-20240229170946102.png"
alt="image-20240229170946102" />
<figcaption aria-hidden="true">image-20240229170946102</figcaption>
</figure>
<p>在三维的情况下，eigenspace 是过原点的二维平面</p>
<figure>
<img src="https://fyindex.work/PicGo/image-20240229171148615.png"
alt="image-20240229171148615" />
<figcaption aria-hidden="true">image-20240229171148615</figcaption>
</figure>
<h3 id="定理-eigenvalue-of-triangular-matrix">定理 eigenvalue of
triangular matrix</h3>
<p>The eigenvalues of a triangular matrix are the entries on its main in
diagnoal</p>
<p>证明 <span class="math display">\[
\begin{aligned}
A-\lambda I &amp; =\left[\begin{array}{ccc}
a_{11} &amp; a_{12} &amp; a_{13} \\
0 &amp; a_{22} &amp; a_{23} \\
0 &amp; 0 &amp; a_{33}
\end{array}\right]-\left[\begin{array}{ccc}
\lambda &amp; 0 &amp; 0 \\
0 &amp; \lambda &amp; 0 \\
0 &amp; 0 &amp; \lambda
\end{array}\right] \\
&amp; =\left[\begin{array}{ccc}
a_{11}-\lambda &amp; a_{12} &amp; a_{13} \\
0 &amp; a_{22}-\lambda &amp; a_{23} \\
0 &amp; 0 &amp; a_{33}-\lambda
\end{array}\right]
\end{aligned}
\]</span> 当且仅当 <span class="math inline">\((A-\lambda I)
\mathbf{x}=\mathbf{0}\)</span> 有 non-trival 解的时候, <span
class="math inline">\(\lambda\)</span> 才是 <span
class="math inline">\(A\)</span> 的 eigenvalue. (<span
class="math inline">\(x \ne 0\)</span> )
这个时候肯定是列是线性相关的，不然解出来的 <span
class="math inline">\(x\)</span> 肯定是 <span
class="math inline">\(0\)</span> .也就是 <span
class="math inline">\(\lambda = a_{11},a_{22},a_{33}\)</span> 的时候</p>
<h3 id="结论-eigenvalue-0">结论 eigenvalue 0</h3>
<p>0 is eigenvalue of <span class="math inline">\(A\)</span> if and only
if <span class="math inline">\(A\)</span> is not invertible.</p>
<h3 id="定理-linearly-independence-of-eigenvector">定理 linearly
independence of eigenvector</h3>
<p>If <span class="math inline">\(\mathbf{v}_1, \ldots,
\mathbf{v}_r\)</span> are eignenvectors to distinct eigenvalues <span
class="math inline">\(\lambda_1, \ldots, \lambda_r\)</span> of <span
class="math inline">\(A\)</span> , then the vectors are linerly
independent</p>
<p>证明</p>
<p>反证法：假设 <span class="math inline">\(\mathbf{v}_1, \ldots,
\mathbf{v}_r\)</span> are eignenvectors 是 dependent, 那么 <span
class="math display">\[
c_1 \mathbf{v}_1+\cdots+c_p \mathbf{v}_p=\mathbf{v}_{p+1}
\]</span> 有因为 <span class="math inline">\(Av=\lambda v\)</span>所以
<span class="math display">\[
c_1 \lambda_1 \mathbf{v}_1+\cdots+c_p \lambda_p
\mathbf{v}_p=\lambda_{p+1} \mathbf{v}_{p+1}
\]</span> 前一个式子乘 <span class="math inline">\(\lambda{p+1}\)</span>
然后相减得到 <span class="math display">\[
c_1\left(\lambda_1-\lambda_{p+1}\right)
\mathbf{v}_1+\cdots+c_p\left(\lambda_p-\lambda_{p+1}\right)
\mathbf{v}_p=\mathbf{0}
\]</span> 因为<span class="math inline">\(v_1,...,v_p\)</span> 是
independent, 所以 <span class="math inline">\(\lambda_i =
\lambda_{p+1}\)</span> 这和distinct $$ 矛盾了</p>
<h3 id="properties-1">Properties</h3>
<h4 id="symmetric">symmetric</h4>
<p>A matrix <span class="math inline">\(\boldsymbol{A} \in \mathbb{R}^{m
\times n}\)</span> , <span
class="math inline">\(\boldsymbol{S}:=\boldsymbol{A}^{\top}
\boldsymbol{A}\)</span> <span class="math inline">\(\in \mathbb{R}^{n
\times n}\)</span> is symmetric, positive semidefinite, if <span
class="math inline">\(\operatorname{rk}(\boldsymbol{A})=n\)</span> then
positive definite.</p>
<h4 id="eigenvalues">eigenvalues</h4>
<p>The determinant of a matrix <span
class="math inline">\(\boldsymbol{A} \in \mathbb{R}^{n \times
n}\)</span> is the product of eigenvalues <span class="math display">\[
\operatorname{det}(\boldsymbol{A})=\prod_{i=1}^n \lambda_i
\]</span> The trace of a matrix <span
class="math inline">\(\boldsymbol{A} \in \mathbb{R}^{n \times
n}\)</span> is the sum of eigenvalues <span class="math display">\[
\operatorname{tr}(\boldsymbol{A})=\sum_{i=1}^n \lambda_i
\]</span></p>
<h3 id="similarity">Similarity</h3>
<p><span class="math inline">\(A,B\)</span> are <span
class="math inline">\(n\times n\)</span> matrices. <span
class="math inline">\(A\)</span> is similar to <span
class="math inline">\(B\)</span> if there is an invertible matrix <span
class="math inline">\(P\)</span> such that <span
class="math inline">\(P^{-1}AP=B\)</span> or <span
class="math inline">\(A=PBP^{-1}\)</span> , Writing <span
class="math inline">\(Q=P^{-1}\)</span> ,we have <span
class="math inline">\(Q^{-1}BQ=A\)</span> . So <span
class="math inline">\(B\)</span> is also similar to <span
class="math inline">\(A\)</span></p>
<h4 id="定理-similar-and-eigenvalue">定理 similar and eigenvalue</h4>
<p>if <span class="math inline">\(A\)</span> and <span
class="math inline">\(B\)</span> are similar, then they have same
characteristic polynomial and same eigenvalues</p>
<p>证明</p>
<p><span class="math inline">\(B-\lambda I = P^{-1}AP - \lambda I =
P^{-1}AP - \lambda P^{-1}P = P^{-1}(AP-\lambda P) = P^{-1}(A-\lambda I)
P\)</span></p>
<p><span class="math inline">\(det(B-\lambda I) = det(P^{-1})
det(A-\lambda I) det(P) = det(A-\lambda I)\)</span></p>
<h3 id="diagnoalization">Diagnoalization</h3>
<p>To compute <span class="math inline">\(A^k\)</span> fast, we can
decomposite <span class="math inline">\(A=PDP^{-1}\)</span></p>
<p>then <span class="math inline">\(A^2 = (PDP^{-1})(PDP^{-1})=
PD^2P^{-1}\)</span> . 对于对角矩阵 <span
class="math inline">\(D\)</span> , 它的幂是很好算的 <span
class="math display">\[
A^k=PD^kP^{-1}
\]</span></p>
<h4 id="定理-diagnoalizable">定理 Diagnoalizable</h4>
<p>A <span class="math inline">\(n\times n\)</span> matric <span
class="math inline">\(A\)</span> is diagnoalizable if and only if <span
class="math inline">\(A\)</span> has n linearly independent
eigenvectors. This case, the columns of <span
class="math inline">\(P\)</span> are <span
class="math inline">\(n\)</span> linearly independent eigenvectors of
<span class="math inline">\(A\)</span></p>
<p>证明</p>
<p><span class="math display">\[
A P=A\left[\begin{array}{llll}
\mathbf{v}_1 &amp; \mathbf{v}_2 &amp; \cdots &amp; \mathbf{v}_n
\end{array}\right]=\left[\begin{array}{llll}
A \mathbf{v}_1 &amp; A \mathbf{v}_2 &amp; \cdots &amp; A \mathbf{v}_n
\end{array}\right]
\]</span> with <span class="math display">\[
P D=P\left[\begin{array}{cccc}
\lambda_1 &amp; 0 &amp; \cdots &amp; 0 \\
0 &amp; \lambda_2 &amp; \cdots &amp; 0 \\
\vdots &amp; \vdots &amp; &amp; \vdots \\
0 &amp; 0 &amp; \cdots &amp; \lambda_n
\end{array}\right]=\left[\begin{array}{llll}
\lambda_1 \mathbf{v}_1 &amp; \lambda_2 \mathbf{v}_2 &amp; \cdots &amp;
\lambda_n \mathbf{v}_n
\end{array}\right]
\]</span> Suppose <span class="math inline">\(A\)</span> diagnoalizable
<span class="math inline">\(A=PDP^{-1}\)</span> Then <span
class="math inline">\(AP=PD\)</span> then <span
class="math inline">\(A\mathbf{v_{i}}=\lambda_{i}\mathbf{v_i}\)</span></p>
<h4 id="推论">推论</h4>
<p>A <span class="math inline">\(n\times n\)</span> matric <span
class="math inline">\(A\)</span> with <span
class="math inline">\(n\)</span> distinct eigenvalues is
diagnoalizable</p>
<h3 id="the-matrix-of-a-linear-transformation">The Matrix of a Linear
Transformation</h3>
<figure>
<img src="https://fyindex.work/PicGo/image-20240307151139872.png"
alt="image-20240307151139872" />
<figcaption aria-hidden="true">image-20240307151139872</figcaption>
</figure>
<p><span class="math inline">\(T\)</span> 是任意的Linear Transformation
from <span class="math inline">\(\mathcal{B}\)</span> to <span
class="math inline">\(\mathcal{C}\)</span></p>
<p>把 <span class="math inline">\(\mathbf{x}\)</span> 写成 Base <span
class="math inline">\(\mathcal{B}\)</span> 的形式: <span
class="math display">\[
[\mathbf{x}]_{\mathcal{B}}=\left[\begin{array}{c}
r_1 \\
\vdots \\
r_n
\end{array}\right]
\]</span> 也就是 <span class="math inline">\(\mathbf{x}=r_1
\mathbf{b}_1+\cdots+r_n \mathbf{b}_n\)</span></p>
<p>那么可以计算 <span class="math inline">\(T(\mathbf{x})\)</span> <span
class="math display">\[
T(\mathbf{x})=T\left(r_1 \mathbf{b}_1+\cdots+r_n \mathbf{b}_n\right)=r_1
T\left(\mathbf{b}_1\right)+\cdots+r_n T\left(\mathbf{b}_n\right)
\]</span> 把它写成 base <span class="math inline">\(\mathcal{C}\)</span>
的形式 <span class="math display">\[
[T(\mathbf{x})]_{\mathcal{C}}=r_1\left[T\left(\mathbf{b}_1\right)\right]_{\mathcal{C}}+\cdots+r_n\left[T\left(\mathbf{b}_n\right)\right]_{\mathcal{C}}
\]</span> 把这个变换写成矩阵的形式 <span class="math display">\[
[T(\mathbf{x})]_{\mathcal{C}}=M[\mathbf{x}]_{\mathcal{B}}
\]</span></p>
<p><span class="math display">\[
M=\left[\begin{array}{llll}
{\left[T\left(\mathbf{b}_1\right)\right]_{\mathcal{C}}} &amp;
{\left[T\left(\mathbf{b}_2\right)\right]_{\mathcal{C}}} &amp; \cdots
&amp; {\left[T\left(\mathbf{b}_n\right)\right]_{\mathcal{C}}}
\end{array}\right]
\]</span></p>
<p><span class="math inline">\(M\)</span> 就是 matrix representation of
<span class="math inline">\(T\)</span> relative to the bases <span
class="math inline">\(\mathcal{B}\)</span> and <span
class="math inline">\(\mathcal{C}\)</span></p>
<h2 id="the-singular-value-decomposition">The Singular Value
Decomposition</h2>
<h3 id="orthonormal-sets">Orthonormal Sets</h3>
<p>A set <span class="math inline">\(\left\{\mathbf{u}_1, \ldots,
\mathbf{u}_p\right\}\)</span> is is an orthonormal set if it is an
<strong>orthogonal</strong> set of unit vectors. 若 <span
class="math inline">\(W\)</span> 是 subspace spanned by such a set，
那么它是 <span class="math inline">\(W\)</span> 的 orthogonal basis.</p>
<h4 id="定理-orthonormal-columns">定理 orthonormal columns</h4>
<p>An <span class="math inline">\(m \times n\)</span> matrix <span
class="math inline">\(U\)</span> has orthonormal columns if and only if
<span class="math inline">\(U^T U=I\)</span></p>
<h4 id="定理-orthonormal-property">定理 orthonormal property</h4>
<p>Let <span class="math inline">\(U\)</span> be an <span
class="math inline">\(m \times n\)</span> matrix with orthonormal
columns， let <span class="math inline">\(\mathbf{x}\)</span> and <span
class="math inline">\(\mathbf{y}\)</span> be in <span
class="math inline">\(\mathbb{R}^n\)</span></p>
<ul>
<li><span class="math inline">\(\|U
\mathbf{x}\|=\|\mathbf{x}\|\)</span></li>
<li><span class="math inline">\((U \mathbf{x}) \cdot(U
\mathbf{y})=\mathbf{x} \cdot \mathbf{y}\)</span></li>
<li><span class="math inline">\((U \mathbf{x}) \cdot(U
\mathbf{y})=0\)</span> if and only if <span
class="math inline">\(\mathbf{x} \cdot \mathbf{y}=0\)</span></li>
</ul>
<p>This means that orthogonal matrices A with A ⊤ = A −1 preserve both
angles and distances. It turns out that orthogonal matrices define
transformations that are rotations (with the possibility of flips).</p>
<h3 id="the-absolute-values-of-the-eigenvalues">The absolute values of
the eigenvalues</h3>
<p>The singular value decomposition is based on the following property
of the ordinary diagonalization that can be imitated for rectangular
matrices: The absolute values of the eigenvalues of a symmetric matrix A
measure the amounts that <span class="math inline">\(A\)</span>
stretches or shrinks certain vectors (the eigenvectors).</p>
<p>If <span class="math inline">\(A \mathbf{x}=\lambda
\mathbf{x}\)</span> and <span
class="math inline">\(\|\mathbf{x}\|=1\)</span> then <span
class="math display">\[
\|A \mathbf{x}\|=\|\lambda
\mathbf{x}\|=|\lambda|\|\mathbf{x}\|=|\lambda|
\]</span> 设 <span class="math inline">\(A\)</span> 是 <span
class="math inline">\(m \times n\)</span> 矩阵， <span
class="math inline">\(A^TA\)</span> 是 symmetric 并且可以 orthogonally
diagonalized. 设 <span class="math inline">\(\left\{\mathbf{v}_1,
\ldots, \mathbf{v}_n\right\}\)</span> 是 <span
class="math inline">\(A^TA\)</span> 的 由eigenvectors组成的 orthonormal
basis , <span class="math inline">\(\lambda_1, \ldots,
\lambda_n\)</span> 是对应的 eigenvalues. <span class="math display">\[
\begin{aligned}
\left\|A \mathbf{v}_i\right\|^2 &amp;=\left(A \mathbf{v}_i\right)^T A
\mathbf{v}_i=\mathbf{v}_i^T A^T A \mathbf{v}_i \\
&amp; =\mathbf{v}_i^T\left(\lambda_i \mathbf{v}_i\right)  \\
&amp; =\lambda_i \quad \\
&amp;
\end{aligned}
\]</span> So the eigenvalues of <span
class="math inline">\(A^TA\)</span> are all nonnegative</p>
<h3 id="singular-value">singular value</h3>
<p>the <strong>singular values</strong> of A are the lengths of the
vectors <span class="math inline">\(A \mathbf{v}_1, \ldots, A
\mathbf{v}_n\)</span>, 用 <span class="math inline">\(\sigma_1, \ldots,
\sigma_n\)</span> 降序表示 <span
class="math inline">\(\sigma_i=\sqrt{\lambda_i}\)</span> for <span
class="math inline">\(1 \leq i \leq n\)</span></p>
<h3 id="定理-orthonormal-basis">定理 orthonormal basis</h3>
<p>若 <span class="math inline">\(\left\{\mathbf{v}_1, \ldots,
\mathbf{v}_n\right\}\)</span> 是一个 orthonormal basis of <span
class="math inline">\(\mathbb{R}^n\)</span> , 由 <span
class="math inline">\(A^TA\)</span> 的 eigenvalues
组成，其中的eigenvalues 降序 <span class="math inline">\(\lambda_1 \geq
\cdots \geq \lambda_n\)</span> 并且 <span
class="math inline">\(A\)</span> 有 <span
class="math inline">\(r\)</span> 个非零的 singular values. 那么 <span
class="math inline">\(\left\{A \mathbf{v}_1, \ldots, A
\mathbf{v}_r\right\}\)</span> 是 <span
class="math inline">\(\operatorname{Col} A\)</span> 的 orthonormal basis
并且 <span class="math inline">\(\operatorname{rank} A=r\)</span></p>
<h3 id="定理-the-singular-value-decomposition">定理 The Singular Value
Decomposition</h3>
<p>Let <span class="math inline">\(A\)</span> be an <span
class="math inline">\(m \times n\)</span> matrix with rank <span
class="math inline">\(r\)</span>. Then there exists an <span
class="math inline">\(m \times n\)</span> matrix <span
class="math inline">\(\Sigma\)</span> as <span
class="math inline">\(\Sigma=\left[\begin{array}{rr}D &amp; 0 \\ 0 &amp;
0\end{array}\right]\)</span> which the diagonal entries in <span
class="math inline">\(D\)</span> are the first <span
class="math inline">\(r\)</span> singular values of <span
class="math inline">\(A\)</span>, <span class="math inline">\(\sigma_1
\geq \sigma_2 \geq \cdots \geq \sigma_r&gt;0\)</span>, and there exist
an <span class="math inline">\(m \times m\)</span> orthogonal matrix
<span class="math inline">\(U\)</span> and an <span
class="math inline">\(n \times n\)</span> orthogonal matrix <span
class="math inline">\(V\)</span> such that <span class="math display">\[
A=U \Sigma V^T
\]</span></p>
<h2 id="matrix-calculus">Matrix Calculus</h2>
<h3 id="gradients-of-vectors">Gradients of Vectors</h3>
<p><span class="math inline">\(f: \mathbb{R}^{m \times n} \rightarrow
\mathbb{R}\)</span> <span class="math display">\[
\nabla_A f(A) \in \mathbb{R}^{m \times n}=\left[\begin{array}{cccc}
\frac{\partial f(A)}{\partial A_{11}} &amp; \frac{\partial
f(A)}{\partial A_{12}} &amp; \cdots &amp; \frac{\partial f(A)}{\partial
A_{1 n}} \\
\frac{\partial f(A)}{\partial A_{21}} &amp; \frac{\partial
f(A)}{\partial A_{22}} &amp; \cdots &amp; \frac{\partial f(A)}{\partial
A_{2 n}} \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
\frac{\partial f(A)}{\partial A_{m 1}} &amp; \frac{\partial
f(A)}{\partial A_{m 2}} &amp; \cdots &amp; \frac{\partial f(A)}{\partial
A_{m n}}
\end{array}\right]
\]</span></p>
<p><span class="math display">\[
\nabla_x f(x)=\left[\begin{array}{c}
\frac{\partial f(x)}{\partial x_1} \\
\frac{\partial f(x)}{\partial x_2} \\
\vdots \\
\frac{\partial f(x)}{\partial x_n}
\end{array}\right]
\]</span></p>
<p>For a function <span class="math inline">\(\boldsymbol{f}:
\mathbb{R}^n \rightarrow \mathbb{R}^m\)</span> and a vector <span
class="math inline">\(\boldsymbol{x}=\left[x_1, \ldots,
x_n\right]^{\top} \in \mathbb{R}^n\)</span> then the vector function
<span class="math display">\[
\boldsymbol{f}(\boldsymbol{x})=\left[\begin{array}{c}
f_1(\boldsymbol{x}) \\
\vdots \\
f_m(\boldsymbol{x})
\end{array}\right] \in \mathbb{R}^m
\]</span> The gradient is <span class="math display">\[
\frac{\partial \boldsymbol{f}}{\partial x_i}=\left[\begin{array}{c}
\frac{\partial f_1}{\partial x_i} \\
\vdots \\
\frac{\partial f_m}{\partial x_i}
\end{array}\right]=\left[\begin{array}{c}
\lim _{h \rightarrow 0} \frac{f_1\left(x_1, \ldots, x_{i-1}, x_i+h,
x_{i+1}, \ldots x_n\right)-f_1(\boldsymbol{x})}{h} \\
\vdots \\
\lim _{h \rightarrow 0} \frac{f_m\left(x_1, \ldots, x_{i-1}, x_i+h,
x_{i+1}, \ldots x_n\right)-f_m(\boldsymbol{x})}{h}
\end{array}\right] \in \mathbb{R}^m
\]</span> The Jacobian <span
class="math inline">\(\boldsymbol{J}\)</span> is an <span
class="math inline">\(m \times n\)</span> matrix <span
class="math display">\[
\begin{aligned}
\boldsymbol{J} &amp; =\nabla_{\boldsymbol{x}}
\boldsymbol{f}=\frac{\mathrm{d}
\boldsymbol{f}(\boldsymbol{x})}{\mathrm{d}
\boldsymbol{x}}=\left[\begin{array}{ccc}
\frac{\partial \boldsymbol{f}(\boldsymbol{x})}{\partial x_1} &amp;
\ldots &amp; \frac{\partial \boldsymbol{f}(\boldsymbol{x})}{\partial
x_n}
\end{array}\right] \\
&amp; =\left[\begin{array}{ccc}
\frac{\partial f_1(\boldsymbol{x})}{\partial x_1} &amp; \cdots &amp;
\frac{\partial f_1(\boldsymbol{x})}{\partial x_n} \\
\vdots &amp; \vdots \\
\frac{\partial f_m(\boldsymbol{x})}{\partial x_1} &amp; \ldots &amp;
\frac{\partial f_m(\boldsymbol{x})}{\partial x_n}
\end{array}\right], \\
\boldsymbol{x} &amp; =\left[\begin{array}{c}
x_1 \\
\vdots \\
x_n
\end{array}\right], \quad J(i, j)=\frac{\partial f_i}{\partial x_j} .
\end{aligned}
\]</span> Consider <span class="math display">\[
\boldsymbol{f}(\boldsymbol{x})=\boldsymbol{A} \boldsymbol{x}, \quad
\boldsymbol{f}(\boldsymbol{x}) \in \mathbb{R}^M, \quad \boldsymbol{A}
\in \mathbb{R}^{M \times N}, \quad \boldsymbol{x} \in \mathbb{R}^N
\]</span></p>
<p><span class="math display">\[
f_i(\boldsymbol{x})=\sum_{j=1}^N A_{i j} x_j \Longrightarrow
\frac{\partial f_i}{\partial x_j}=A_{i j}
\]</span></p>
<p><span class="math display">\[
\frac{\mathrm{d} \boldsymbol{f}}{\mathrm{d}
\boldsymbol{x}}=\left[\begin{array}{ccc}
\frac{\partial f_1}{\partial x_1} &amp; \cdots &amp; \frac{\partial
f_1}{\partial x_N} \\
\vdots &amp; &amp; \vdots \\
\frac{\partial f_M}{\partial x_1} &amp; \cdots &amp; \frac{\partial
f_M}{\partial x_N}
\end{array}\right]=\left[\begin{array}{ccc}
A_{11} &amp; \cdots &amp; A_{1 N} \\
\vdots &amp; &amp; \vdots \\
A_{M 1} &amp; \cdots &amp; A_{M N}
\end{array}\right]=\boldsymbol{A} \in \mathbb{R}^{M \times N}
\]</span></p>
<h3 id="gradients-of-matrices">Gradients of Matrices</h3>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>Author: </span><span class="post-copyright-info"><a href="http://fyind.de">Fyind</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>Link: </span><span class="post-copyright-info"><a href="http://fyind.de/2024/02/29/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E9%87%8D%E8%A6%81%E6%A6%82%E5%BF%B5/">http://fyind.de/2024/02/29/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E9%87%8D%E8%A6%81%E6%A6%82%E5%BF%B5/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>Copyright Notice: </span><span class="post-copyright-info">All articles on this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless otherwise stated.</span></div></div><div class="tag_share"><div class="post-share"><div class="social-share" data-image="/img/pic1.PNG" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/2024/03/12/%E6%B3%95%E8%AF%AD%E5%85%A5%E9%97%A8/" title="法语入门"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info"><div class="info-1"><div class="info-item-1">Previous</div><div class="info-item-2">法语入门</div></div><div class="info-2"><div class="info-item-1">Keyboard   undefined  问候  Bonsoir! Tu vas bien? - Oui, et tui?  Bonsua, Tue va bian, we, e tua  Salut ! Ça va? Ça va, Et tui.  salu sa va, sa va etua  Bonjour, vous allez bien?  vo sa le bian  Au revoir! Salut!  o revoa salu     词性 阳: un tableau 黑板  an tablu  un ordinateur 笔记本电脑  an nordinater  un smartphone 手机 un cahier 笔记本  an kaye  un livre 书  lievra  un stylo 圆珠笔  stilo  un crayon 铅笔  creyong  阴 une chaise 椅子  uen shese  une table 桌子  tabla  une tablette 平板电脑  tablete    字母表 和德语不同的 C, E, ...</div></div></div></a><a class="pagination-related" href="/2024/02/22/%E5%B5%8C%E5%85%A5%E5%BC%8F%E7%B3%BB%E7%BB%9F%E5%92%8C%E5%AE%89%E5%85%A8/" title="嵌入式系统和安全"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-right"><div class="info-1"><div class="info-item-1">Next</div><div class="info-item-2">嵌入式系统和安全</div></div><div class="info-2"><div class="info-item-1">嵌入式系统和安全 Introduction Four requirements for embedded system  Efficiency, function,dependability, security  Relationship between Dependability and security Difference between security and safety Goal of lecture   Being able to design secure embedded systems Assess and choose appropriate measures to secure an embedded system Implement given tasks on an embedded system (done) Use toolchains for cross-platform development Discuss memory organization Classify different types of on-chip memory Reca...</div></div></div></a></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/img/pic1.PNG" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">Fyind</div><div class="author-info-description"></div><div class="site-data"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">85</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">83</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">26</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/Fyind"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons"><a class="social-icon" href="https://github.com/Fyind" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:tarjan0025@gmail.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a><a class="social-icon" href="https://jq.qq.com/?_wv=1027&amp;k=d0kMY0nN" target="_blank" title="QQ"><i class="fab fa-qq"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>Announcement</span></div><div class="announcement_content">欢迎来逛逛我的博客</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Contents</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#matrix-algebra"><span class="toc-number">1.</span> <span class="toc-text">Matrix Algebra</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9A%E7%90%86-%E5%9F%BA%E6%9C%AC%E8%BF%90%E7%AE%97"><span class="toc-number">1.1.</span> <span class="toc-text">定理 基本运算</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#matrix-multiplication"><span class="toc-number">1.2.</span> <span class="toc-text">Matrix Multiplication</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9A%E7%90%86-%E4%B9%98%E6%B3%95%E7%9A%84%E6%80%A7%E8%B4%A8"><span class="toc-number">1.3.</span> <span class="toc-text">定理 乘法的性质</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#the-transpose-of-a-matrix"><span class="toc-number">1.4.</span> <span class="toc-text">The Transpose of a Matrix</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#inverse-matrix"><span class="toc-number">1.5.</span> <span class="toc-text">inverse matrix</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#vector-space-and-subspaces"><span class="toc-number">2.</span> <span class="toc-text">vector space and subspaces</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#vector-space"><span class="toc-number">2.1.</span> <span class="toc-text">vector space</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#subspace"><span class="toc-number">2.2.</span> <span class="toc-text">subspace</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#the-null-space-of-a-matrix"><span class="toc-number">2.3.</span> <span class="toc-text">The Null Space of a Matrix</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#properties-of-determinants"><span class="toc-number">2.4.</span> <span class="toc-text">Properties of Determinants</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#find-span"><span class="toc-number">2.5.</span> <span class="toc-text">Find span</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#rank"><span class="toc-number">2.6.</span> <span class="toc-text">Rank</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#linear-mapping"><span class="toc-number">3.</span> <span class="toc-text">Linear Mapping</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#image"><span class="toc-number">3.0.1.</span> <span class="toc-text">Image</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#null-space-and-column-space"><span class="toc-number">3.1.</span> <span class="toc-text">Null Space and Column Space</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#transformation-matrix"><span class="toc-number">3.2.</span> <span class="toc-text">Transformation Matrix</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#traces"><span class="toc-number">4.</span> <span class="toc-text">Traces</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#properties"><span class="toc-number">4.1.</span> <span class="toc-text">properties</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#eignevalue-and-eigenvector"><span class="toc-number">5.</span> <span class="toc-text">Eignevalue and Eigenvector</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#eigenvector"><span class="toc-number">5.1.</span> <span class="toc-text">Eigenvector</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9A%E7%90%86-eigenvalue-of-triangular-matrix"><span class="toc-number">5.2.</span> <span class="toc-text">定理 eigenvalue of
triangular matrix</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BB%93%E8%AE%BA-eigenvalue-0"><span class="toc-number">5.3.</span> <span class="toc-text">结论 eigenvalue 0</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9A%E7%90%86-linearly-independence-of-eigenvector"><span class="toc-number">5.4.</span> <span class="toc-text">定理 linearly
independence of eigenvector</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#properties-1"><span class="toc-number">5.5.</span> <span class="toc-text">Properties</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#symmetric"><span class="toc-number">5.5.1.</span> <span class="toc-text">symmetric</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#eigenvalues"><span class="toc-number">5.5.2.</span> <span class="toc-text">eigenvalues</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#similarity"><span class="toc-number">5.6.</span> <span class="toc-text">Similarity</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AE%9A%E7%90%86-similar-and-eigenvalue"><span class="toc-number">5.6.1.</span> <span class="toc-text">定理 similar and eigenvalue</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#diagnoalization"><span class="toc-number">5.7.</span> <span class="toc-text">Diagnoalization</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AE%9A%E7%90%86-diagnoalizable"><span class="toc-number">5.7.1.</span> <span class="toc-text">定理 Diagnoalizable</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%8E%A8%E8%AE%BA"><span class="toc-number">5.7.2.</span> <span class="toc-text">推论</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#the-matrix-of-a-linear-transformation"><span class="toc-number">5.8.</span> <span class="toc-text">The Matrix of a Linear
Transformation</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#the-singular-value-decomposition"><span class="toc-number">6.</span> <span class="toc-text">The Singular Value
Decomposition</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#orthonormal-sets"><span class="toc-number">6.1.</span> <span class="toc-text">Orthonormal Sets</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AE%9A%E7%90%86-orthonormal-columns"><span class="toc-number">6.1.1.</span> <span class="toc-text">定理 orthonormal columns</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AE%9A%E7%90%86-orthonormal-property"><span class="toc-number">6.1.2.</span> <span class="toc-text">定理 orthonormal property</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#the-absolute-values-of-the-eigenvalues"><span class="toc-number">6.2.</span> <span class="toc-text">The absolute values of
the eigenvalues</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#singular-value"><span class="toc-number">6.3.</span> <span class="toc-text">singular value</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9A%E7%90%86-orthonormal-basis"><span class="toc-number">6.4.</span> <span class="toc-text">定理 orthonormal basis</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9A%E7%90%86-the-singular-value-decomposition"><span class="toc-number">6.5.</span> <span class="toc-text">定理 The Singular Value
Decomposition</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#matrix-calculus"><span class="toc-number">7.</span> <span class="toc-text">Matrix Calculus</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#gradients-of-vectors"><span class="toc-number">7.1.</span> <span class="toc-text">Gradients of Vectors</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#gradients-of-matrices"><span class="toc-number">7.2.</span> <span class="toc-text">Gradients of Matrices</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Posts</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/07/17/C-%E9%AB%98%E6%80%A7%E8%83%BD%E7%BC%96%E7%A8%8B/" title="C++高性能编程">C++高性能编程</a><time datetime="2025-07-17T19:47:19.000Z" title="Created 2025-07-17 19:47:19">2025-07-17</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/07/16/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E6%A6%82%E5%BF%B5/" title="操作系统概念">操作系统概念</a><time datetime="2025-07-16T20:55:14.000Z" title="Created 2025-07-16 20:55:14">2025-07-16</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/07/15/Kubuntu%E9%85%8D%E7%BD%AE/" title="Kubuntu配置">Kubuntu配置</a><time datetime="2025-07-15T05:25:37.000Z" title="Created 2025-07-15 05:25:37">2025-07-15</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/07/12/%E6%88%91%E4%BB%AC%E5%9C%A8AI%E6%97%B6%E4%BB%A3%E8%AF%A5%E5%A6%82%E4%BD%95%E5%AD%A6%E4%B9%A0/" title="我们在AI时代该如何学习">我们在AI时代该如何学习</a><time datetime="2025-07-12T23:12:19.000Z" title="Created 2025-07-12 23:12:19">2025-07-12</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/07/12/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9CA-Top-Down-Approach/" title="计算机网络A Top Down Approach">计算机网络A Top Down Approach</a><time datetime="2025-07-12T22:02:58.000Z" title="Created 2025-07-12 22:02:58">2025-07-12</time></div></div></div></div></div></div></main><footer id="footer"><div class="footer-other"><div class="footer-copyright"><span class="copyright">&copy;2025 By Fyind</span><span class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo 7.3.0</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly 5.4.2</a></span></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Reading Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Toggle Between Light and Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle Between Single-column and Double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="Settings"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table of Contents"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="Back to Top"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"><script>(() => {
  const loadMathjax = () => {
    if (!window.MathJax) {
      window.MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          tags: 'all',
        },
        chtml: {
          scale: 1.1
        },
        options: {
          enableMenu: true,
          renderActions: {
            findScript: [10, doc => {
              for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
                const display = !!node.type.match(/; *mode=display/)
                const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
                const text = document.createTextNode('')
                node.parentNode.replaceChild(text, node)
                math.start = {node: text, delim: '', n: 0}
                math.end = {node: text, delim: '', n: 0}
                doc.math.push(math)
              }
            }, '']
          }
        }
      }

      const script = document.createElement('script')
      script.src = 'https://cdn.jsdelivr.net/npm/mathjax/es5/tex-mml-chtml.min.js'
      script.id = 'MathJax-script'
      script.async = true
      document.head.appendChild(script)
    } else {
      MathJax.startup.document.state(0)
      MathJax.texReset()
      MathJax.typesetPromise()
    }
  }

  btf.addGlobalFn('encrypt', loadMathjax, 'mathjax')
  window.pjax ? loadMathjax() : window.addEventListener('load', loadMathjax)
})()</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>